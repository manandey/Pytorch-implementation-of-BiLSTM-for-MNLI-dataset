{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BiLSTM_MNLI.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jF2aIwCE5FYX"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchtext\n",
        "from torchtext import data\n",
        "from torchtext.data import Field, Iterator\n",
        "from torchtext import datasets\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import re\n",
        "import time\n",
        "import numpy as np\n",
        "import spacy\n",
        "from spacy.tokenizer import Tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQZUKSyExQXg"
      },
      "source": [
        "!python -m spacy download en"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJkCw9oizrSM"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4Wl39LO7fTT"
      },
      "source": [
        "nlp = spacy.load(\"en\")\n",
        "tokenizer = Tokenizer(nlp.vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yL2P3L465Lu"
      },
      "source": [
        "def spacy_tokenize(x):\n",
        "    x = re.sub(\n",
        "        r\"[\\*\\\"“”\\n\\\\…\\+\\-\\/\\=\\(\\)‘•:\\[\\]\\|’\\!;]\", \" \", \n",
        "        str(x))\n",
        "    x = re.sub(r\"[ ]+\", \" \", x)\n",
        "    x = re.sub(r\"\\!+\", \"!\", x)\n",
        "    x = re.sub(r\"\\,+\", \",\", x)\n",
        "    x = re.sub(r\"\\?+\", \"?\", x)\n",
        "    return [tok.text for tok in tokenizer(x) if tok.text != \" \"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHU3QxT269P2"
      },
      "source": [
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeJn6isy7A96"
      },
      "source": [
        "path = ('/content/drive/My Drive/Colab Notebooks/NLI/NLI_Datasets/')\n",
        "\n",
        "TEXT = data.Field(lower=True, tokenize = spacy_tokenize, batch_first = True)\n",
        "LABEL = data.LabelField(sequential=False, is_target = True)\n",
        "\n",
        "fields = {'sentence1': ('premise', TEXT),\n",
        "          'sentence2': ('hypothesis', TEXT),\n",
        "          'gold_label': ('label', LABEL)}\n",
        "\n",
        "train, dev, test = data.TabularDataset.splits(\n",
        "    path=path, \n",
        "    train=('mnli_train.jsonl'),\n",
        "    validation=('mnli_dev.jsonl'),\n",
        "    test=('mnli_test.jsonl'),\n",
        "    format='json', \n",
        "    fields=fields\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbwsGogqBcu0"
      },
      "source": [
        "print(f'Number of training examples: {len(train)}')\n",
        "print(f'Number of valid examples: {len(dev)}')\n",
        "print(f'Number of testing examples: {len(test)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eQWDnpRyXIg"
      },
      "source": [
        "print(vars(train.examples[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSf1reONBn0F"
      },
      "source": [
        "print(vars(test.examples[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3GCjk18Bt4x"
      },
      "source": [
        "TEXT.build_vocab(train, dev, min_freq=2, vectors=torchtext.vocab.Vectors('/content/drive/My Drive/Colab Notebooks/NLI/Glove/glove.6B.300d.txt', unk_init=torch.Tensor.normal_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVpzsvDiEi8a"
      },
      "source": [
        "LABEL.build_vocab(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmWJSRB7F_KX"
      },
      "source": [
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i16JgdVBF_g8"
      },
      "source": [
        "print(TEXT.vocab.freqs.most_common(10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpjeB6oYF_eq"
      },
      "source": [
        "print(TEXT.vocab.itos[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dG9BVpFiF_Z6"
      },
      "source": [
        "print(LABEL.vocab.itos)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKzAEkxWF_H2"
      },
      "source": [
        "print(LABEL.vocab.freqs.most_common())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qqStSPWF_D3"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iter, dev_iter, test_iter = data.BucketIterator.splits(\n",
        "    (train, dev, test), batch_size=BATCH_SIZE, sort=False, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yatjGT6oGYJN"
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 300\n",
        "HIDDEN_DIM = 200\n",
        "OUTPUT_DIM = len(LABEL.vocab)\n",
        "DP_RATIO = 0.2\n",
        "LEARN_RATE = 0.001"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AncjmW3BGYF9"
      },
      "source": [
        "class BiLSTM(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.embed_dim = EMBEDDING_DIM\n",
        "        self.hidden_size = HIDDEN_DIM\n",
        "        self.directions = 2\n",
        "        self.num_layers = 2\n",
        "        self.concat = 4\n",
        "        self.device = device\n",
        "        self.embedding = nn.Embedding(INPUT_DIM, EMBEDDING_DIM)\n",
        "        self.projection = nn.Linear(self.embed_dim, self.hidden_size)\n",
        "        self.lstm = nn.LSTM(self.hidden_size, self.hidden_size, self.num_layers,\n",
        "                                    bidirectional = True, batch_first = True, dropout = DP_RATIO)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(p = DP_RATIO)\n",
        "\n",
        "        self.lin1 = nn.Linear(self.hidden_size * self.directions * self.concat, self.hidden_size)\n",
        "        self.lin2 = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.lin3 = nn.Linear(self.hidden_size, OUTPUT_DIM)\n",
        "\n",
        "        for lin in [self.lin1, self.lin2, self.lin3]:\n",
        "            nn.init.xavier_uniform_(lin.weight)\n",
        "            nn.init.zeros_(lin.bias)\n",
        "\n",
        "        self.out = nn.Sequential(\n",
        "            self.lin1,\n",
        "            self.relu,\n",
        "            self.dropout,\n",
        "            self.lin2,\n",
        "            self.relu,\n",
        "            self.dropout,\n",
        "            self.lin3\n",
        "        ) \n",
        "        \n",
        "    def forward(self, batch):\n",
        "        premise_embed = self.embedding(batch.premise)\n",
        "        hypothesis_embed = self.embedding(batch.hypothesis)\n",
        "\n",
        "        premise_proj = self.relu(self.projection(premise_embed))\n",
        "        hypothesis_proj = self.relu(self.projection(hypothesis_embed))\n",
        "\n",
        "        h0 = c0 = torch.tensor([]).new_zeros((self.num_layers * self.directions, batch.batch_size, self.hidden_size)).to(self.device)\n",
        "\n",
        "        _, (premise_ht, _) = self.lstm(premise_proj, (h0, c0))\n",
        "        _, (hypothesis_ht, _) = self.lstm(hypothesis_proj, (h0, c0))\n",
        "    \n",
        "        premise = premise_ht[-2:].transpose(0, 1).contiguous().view(batch.batch_size, -1)\n",
        "        hypothesis = hypothesis_ht[-2:].transpose(0, 1).contiguous().view(batch.batch_size, -1)\n",
        "\n",
        "        combined = torch.cat((premise, hypothesis, torch.abs(premise - hypothesis), premise * hypothesis), 1)\n",
        "        return self.out(combined)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgdGiz07GYDN"
      },
      "source": [
        "model = BiLSTM()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDUk_Ro5GX-2"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-QGuhSlGqe1"
      },
      "source": [
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "print(pretrained_embeddings.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRL8kjGSGqYU"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARN_RATE)\n",
        "criterion = nn.CrossEntropyLoss(reduction = 'sum')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJlHiV1IGqUf"
      },
      "source": [
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAu9hQhoGqSH"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "        model.train(); train_iter.init_epoch()\n",
        "        n_correct, n_total, n_loss = 0, 0, 0\n",
        "        for batch_idx, batch in enumerate(train_iter):\n",
        "            optimizer.zero_grad()\n",
        "            answer = model(batch)\n",
        "            loss = criterion(answer, batch.label)\n",
        "            \n",
        "            n_correct += (torch.max(answer, 1)[1].view(batch.label.size()) == batch.label).sum().item()\n",
        "            n_total += batch.batch_size\n",
        "            n_loss += loss.item()\n",
        "            \n",
        "            loss.backward(); optimizer.step()\n",
        "        train_loss = n_loss/n_total\n",
        "        train_acc = 100. * n_correct/n_total\n",
        "        return train_loss, train_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQVZdo21GqPf"
      },
      "source": [
        "def validate(model, iterator, criterion):\n",
        "        model.eval(); test_iter.init_epoch()\n",
        "        n_correct, n_total, n_loss = 0, 0, 0\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, batch in enumerate(test_iter):\n",
        "                answer = model(batch)\n",
        "                loss = criterion(answer, batch.label)\n",
        "                \n",
        "                n_correct += (torch.max(answer, 1)[1].view(batch.label.size()) == batch.label).sum().item()\n",
        "                n_total += batch.batch_size\n",
        "                n_loss += loss.item()\n",
        "\n",
        "            val_loss = n_loss/n_total\n",
        "            val_acc = 100. * n_correct/n_total\n",
        "            return val_loss, val_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tmCbNeNGqJo"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66iIFjCKHEJj"
      },
      "source": [
        "N_EPOCHS = 5\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iter, optimizer, criterion)\n",
        "    valid_loss, valid_acc = validate(model, test_iter, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), '/content/drive/My Drive/Colab Notebooks/NLI/Models/bilstm-mnli-model.pt')\n",
        "        \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc:.2f}%')\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}